{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SureStart Day 18 - Visualizing Overfitting Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYy172Wg3DIh"
      },
      "source": [
        "Exercise from https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4 (Visualizing Loss and Accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DUxnWpk24ek"
      },
      "source": [
        "To know if our model is overfitting, we can plot the training loss and the num of epochs passed. To display some nice graphs, we can use the package matplotlib. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-A7ZzEX3LKG"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HzWG5nN3NXg"
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YG_jbRp3f6F"
      },
      "source": [
        "These commands won't run anything (we have not plugged any data in or made a model to train on) but the above snipppet of code will make a graph showing model loss over the num of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz-WUqRy3t2X"
      },
      "source": [
        "To plot the training accuracy and validation accuracy, use the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StCGZPjr3zjy"
      },
      "source": [
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFCfs41k4FKN"
      },
      "source": [
        "The code will produce a graph that shows model accuracy over the num of epochs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gFEkV34VpW"
      },
      "source": [
        "The snippet of code below shows a method of introducing regularizaton to a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2D8L1To4gAZ"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb45n9YP4mBq"
      },
      "source": [
        "model_3 = Sequential([\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(10,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neF_i_L64pTB"
      },
      "source": [
        "The \"kernel_regularizer=regularizers.12(0.01)\" tells Keras to include the squared values of those parameters in our overal loss function, and to weight them by 0.01 in the loss function. \n",
        "\n",
        "To add Dropout, we added a new layer using \"Dropout(0.3)\" - which means that neurons in the previous layer have a probability of 0.3 of dropping out in training"
      ]
    }
  ]
}